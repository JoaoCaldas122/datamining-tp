{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd6202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import re\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee9d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ano = '202223'\n",
    "url = 'https://fbref.com/pt/comps/32/2022-2023/cronograma/2022-2023-Primeira-Liga-Resultados-e-Calendarios'\n",
    "playoff = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096adc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_update = pd.read_html(url, extract_links=\"all\")\n",
    "df_update = df_update[0]\n",
    "\n",
    "df_update.columns = [col[0] for col in df_update.columns]\n",
    "\n",
    "df_update_getSecondTuple = ['Relatório da Partida']\n",
    "\n",
    "for column in df_update.columns:\n",
    "    if column not in df_update_getSecondTuple:\n",
    "        df_update[column] = df_update[column].apply(lambda x: x[0])\n",
    "    else:\n",
    "        df_update[column] = df_update[column].apply(lambda x: x[1])\n",
    "        \n",
    "if playoff:\n",
    "    df_update = df_update[:-2]\n",
    "    df_update.drop(['Rodada'],inplace=True)\n",
    "            \n",
    "df_update['goals_home'] = df_update['Resultado'].str.split('–').str[0]\n",
    "df_update['goals_away'] = df_update['Resultado'].str.split('–').str[1]\n",
    "df_update.drop(['Resultado','Notas'],axis=1,inplace=True)\n",
    "values = ['None']\n",
    "df_update = df_update[df_update['Relatório da Partida'].isna() == False].reset_index(drop=True) \n",
    "df_update.rename({'xG': 'xG_home', '(': 'xG_away', 'Em casa': 'home', 'Visitante': 'away', 'Público': 'Assistance', 'Sem': 'Jornada'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf1ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da29ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadf0e78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(f'dataset_{ano}.csv')\n",
    "    df.drop('Unnamed: 0',inplace=True)\n",
    "except:\n",
    "    df = df_update.copy()\n",
    "    \n",
    "df_update['Assistance'] =  df_update['Assistance'].str.replace('.', '').replace('', 0)\n",
    "df_update['Assistance'] = df_update['Assistance'].astype(int)\n",
    "df['Assistance'] = df_update['Assistance']\n",
    "\n",
    "for index, row in df[df['Relatório da Partida'].str.startswith('/pt/stathead/')].iterrows():\n",
    "    df.loc[index] = df_update.loc[index]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    if row['Relatório da Partida'].startswith('/pt/partidas/') and ('jogador1_home' not in df.columns or pd.isna(df.loc[index,'jogador1_home'])):\n",
    "    \n",
    "        start = time.time()\n",
    "\n",
    "        url = row['Relatório da Partida']\n",
    "        print(url)\n",
    "        r = requests.get('http://fbref.com' + url)\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        tables = soup.find_all('table')\n",
    "        try:\n",
    "            table = tables[0]\n",
    "            table2 = tables[1] \n",
    "        except Exception:\n",
    "            indice = index\n",
    "        \n",
    "        home_players = pd.read_html(str(table))[0].drop(11)\n",
    "        away_players = pd.read_html(str(table2))[0].drop(11)\n",
    "        df.loc[index,'formacao_home'] = home_players.columns[0].split('(')[1][:-1]\n",
    "        df.loc[index,'formacao_away'] = away_players.columns[0].split('(')[1][:-1]\n",
    "        home_players = home_players.transpose().reset_index().drop('index',axis=1)\n",
    "        away_players = away_players.transpose().reset_index().drop('index',axis=1)\n",
    "\n",
    "        print(f'meio: {time.time() - start}')\n",
    "        \n",
    "        stats_div = soup.find('div', {'id': 'team_stats_extra'})\n",
    "\n",
    "        # extrai o conteúdo da div\n",
    "        stats_text = stats_div.text\n",
    "\n",
    "        linhas = stats_text.split('\\n')\n",
    "        palavras_chave = ['Faltas', 'Escanteios', 'Cruzamentos', 'Contatos', 'Bote defensivo', 'Cortes', 'Jogadas aéreas', 'Defesas', 'Impedimentos', 'Tiro de meta', 'Cobrança de lateral', 'Bolas longas']\n",
    "\n",
    "        lista_strings = [string for string in linhas for palavra in palavras_chave if palavra in string]\n",
    "\n",
    "        nova_lista = []\n",
    "        for string in lista_strings:\n",
    "            match = re.match(r'^(\\d+)([a-zA-Z\\s]+)(\\d+)$', string)\n",
    "            if match:\n",
    "                nova_lista.append([int(match.group(1)), match.group(2).strip(), int(match.group(3))])\n",
    "        \n",
    "        for x in nova_lista:\n",
    "            df.loc[index, f\"{x[1]}_home\"] = x[0]\n",
    "            df.loc[index, f\"{x[1]}_away\"] = x[2]\n",
    "            \n",
    "            \n",
    "        cards = {\n",
    "            'home_team': {\n",
    "                'yellow_card': 0,\n",
    "                'red_card': 0,\n",
    "                'yellow_red_card': 0\n",
    "            },\n",
    "            'away_team': {\n",
    "                'yellow_card': 0,\n",
    "                'red_card': 0,\n",
    "                'yellow_red_card': 0\n",
    "            }\n",
    "        }\n",
    "\n",
    "        home_team_cards_div = soup.find_all('div', class_='cards')[0]\n",
    "        home_team_cards_spans = home_team_cards_div.find_all('span')\n",
    "        for span in home_team_cards_spans:\n",
    "            cards['home_team'][span['class'][0]] += 1\n",
    "\n",
    "        away_team_cards_div = soup.find_all('div', class_='cards')[1]\n",
    "        away_team_cards_spans = away_team_cards_div.find_all('span')\n",
    "        for span in away_team_cards_spans:\n",
    "            cards['away_team'][span['class'][0]] += 1\n",
    "        \n",
    "        df.loc[index, 'yellow_card_home'] = cards['home_team']['yellow_card']\n",
    "        df.loc[index, 'red_card_home'] = cards['home_team']['red_card']\n",
    "        df.loc[index, 'yellow_red_card_home'] = cards['home_team']['yellow_red_card']\n",
    "        df.loc[index, 'yellow_card_away'] = cards['away_team']['yellow_card']\n",
    "        df.loc[index, 'red_card_away'] = cards['away_team']['red_card']\n",
    "        df.loc[index, 'yellow_red_card_away'] = cards['away_team']['yellow_red_card']\n",
    "        \n",
    "        for i in range(len(home_players.columns) - 1):\n",
    "            column_name = f'jogador{i+1}_home'\n",
    "            df.loc[index, column_name] = home_players.iloc[1, i]\n",
    "        for i in range(len(away_players.columns) - 1):\n",
    "            column_name = f'jogador{i+1}_away'\n",
    "            df.loc[index, column_name] = away_players.iloc[1, i]\n",
    "\n",
    "        print(f'fim: {time.time() - start}')\n",
    "        if time.time() - start < 6.0:\n",
    "            time.sleep(6.1 - (time.time() - start))\n",
    "            \n",
    "df.to_csv(f'dataset_{ano}.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3c66b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'dataset_{ano}.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8889a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 538\n",
    "df_538 = pd.read_csv('https://projects.fivethirtyeight.com/soccer-api/club/spi_matches.csv')\n",
    "df_538 = df_538[df_538['league'] == 'Portuguese Liga']\n",
    "df_538 = df_538[df_538['season'] == 2022] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b90295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4995f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_538['league'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1699aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_update = pd.read_html('https://fbref.com/pt/comps/32/cronograma/Primeira-Liga-Resultados-e-Calendarios#sched_2022-2023_32_1', extract_links=\"all\")\n",
    "df_update = df_update[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5f3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = pd.read_csv('output_dataset_exemplo.csv')\n",
    "df.set_index('Unnamed: 0', inplace=True)\n",
    "df_update['Assistance'] =  df_update['Assistance'].str.replace('.', '').replace('', np.nan)\n",
    "df_update['Assistance'] = df_update['Assistance'].astype(float)\n",
    "df['Assistance'] = df_update['Assistance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4435a395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_update.columns = [col[0] for col in df_update.columns]\n",
    "\n",
    "df_update_getSecondTuple = ['Relatório da Partida']\n",
    "\n",
    "for column in df_update.columns:\n",
    "    if column not in df_update_getSecondTuple:\n",
    "        df_update[column] = df_update[column].apply(lambda x: x[0])\n",
    "    else:\n",
    "        df_update[column] = df_update[column].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4249899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_update[df_update['Assistance'].isna() == False]#.reset_index() \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71053bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1204a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = df.compare(df_update)\n",
    "\n",
    "# Seleciona as linhas que são diferentes em df e df_update\n",
    "row_idx = df_diff.index[df_diff.ne(\"\").any(axis=1)]\n",
    "\n",
    "# Substitui as linhas em df pelos valores atualizados em df_update\n",
    "#df.loc[row_idx] = df_update.loc[row_idx]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
